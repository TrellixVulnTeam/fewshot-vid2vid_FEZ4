{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f72ccc4",
   "metadata": {},
   "source": [
    "# Demo: Few-Shot vid2vid (Talking Head/Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe23b8e",
   "metadata": {},
   "source": [
    "給予一張人臉 A 的參考照片，Few-shot vid2vid 能夠將一段影片中的人臉 B 替換成參考照片指定的人臉 A。詳細請看 [README.md](https://github.com/achen353/imaginaire-fsvid2vid/blob/master/README.md)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76f6dc",
   "metadata": {},
   "source": [
    "<img alt='teaser' src='https://nvlabs.github.io/few-shot-vid2vid/web_gifs/illustration.gif' width='600'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73aba7b",
   "metadata": {},
   "source": [
    "## 1. 測試模型運行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725967b",
   "metadata": {},
   "source": [
    "成功 build 好 Docker image 並執行後，先測試模型是否能夠正常運行："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785984c",
   "metadata": {},
   "source": [
    "### 1.1 測試模型能夠正常執行 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ../scripts/test_inference.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1104c",
   "metadata": {},
   "source": [
    "### 1.2 測試模型能夠正常執行 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd12307",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ../scripts/test_training.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf4d",
   "metadata": {},
   "source": [
    "## 2. 模型預測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af1bd0",
   "metadata": {},
   "source": [
    "使用模型進行預測（人臉轉換）時，須先將欲使用的影片（driving video）進行處理，將其轉換成影格照片和相對應的 dlib-68 人臉標記，dlib-68 會在臉部輪廓標記 68 個標記點供模型定位。另外還要準備一張欲使用的人臉照片（reference image）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecea46",
   "metadata": {},
   "source": [
    "### 2.1 準備預測資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e56f82",
   "metadata": {},
   "source": [
    "以下整理預測時需要的資料：\n",
    "1. 影片轉換成的照片 * N （driving video)\n",
    "2. dlib-68 人臉邊框標記 * N （driving video）\n",
    "3. 人臉照片 * 1 (reference image）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20e584",
   "metadata": {},
   "source": [
    "#### 2.1.1 將欲使用的影片放入 `/src/projects/fs_vid2vid/data/driving/videos`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7b5cf",
   "metadata": {},
   "source": [
    "```\n",
    "data\n",
    "└───images（2.1.2 寫入的資料夾）\n",
    "└───landmarks-dlib68（2.1.3 寫入的資料夾）\n",
    "└───videos\n",
    "    └───00000.mp4\n",
    "    └───00001.mp4\n",
    "    └───00002.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6abc27",
   "metadata": {},
   "source": [
    "#### 2.1.2 將影片轉換成影格（driving video to images）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python video_to_frames.py -i projects/fs_vid2vid/data/driving/videos/00000.mp4 -o projects/fs_vid2vid/data/driving/images/00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6abd2",
   "metadata": {},
   "source": [
    "#### 2.1.3 準備臉部輪廓標記（dlib-68 landmarks）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09230d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python facial_landmarks.py -i projects/fs_vid2vid/data/driving/images/00000 -o projects/fs_vid2vid/data/driving/landmarks-dlib68/00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4200e80",
   "metadata": {},
   "source": [
    "#### 2.1.4 將上面寫入 `/images` 和 `/landmarks-dlib68` 的測試資料放入 `/src/projects/fs_vid2vid/test_data/faceForensics/driving`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315d168",
   "metadata": {},
   "source": [
    "```\n",
    "faceForensics\n",
    "└───reference\n",
    "    ...\n",
    "└───driving\n",
    "    └───images\n",
    "         └───00001.jpg\n",
    "         └───00002.jpg\n",
    "        ...\n",
    "    └───landmarks-dlib68\n",
    "         └───00001.json\n",
    "         └───00002.json\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b21596",
   "metadata": {},
   "source": [
    "#### 2.1.5 將參考照片（reference image）放入 `/src/projects/fs_vid2vid/test_data/faceForensics/reference`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732700b",
   "metadata": {},
   "source": [
    "比照 2.1.3 和 2.1.4，取得 reference image（e.g. `00000.jpg`）的臉部標記（e.g. `00000.json`），放入 `/reference` 內（只能放入一組）：\n",
    "```\n",
    "faceForensics\n",
    "└───reference\n",
    "    └───images\n",
    "        └───00000.jpg\n",
    "    └───landmarks-dlib68\n",
    "        └───00000.json\n",
    "└───driving\n",
    "     ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1fd75",
   "metadata": {},
   "source": [
    "### 2.2 進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py --single_gpu --num_workers 0 \\\n",
    "--config configs/projects/fs_vid2vid/face_forensics/ampO1.yaml \\\n",
    "--output_dir projects/fs_vid2vid/output/face_forensics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ace80f",
   "metadata": {},
   "source": [
    "### 2.3 檢視結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video\n",
    "Video.from_file(\"projects/fs_vid2vid/output/face_forensics/001.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
